{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal (2 capas), desde cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "from get_images import get_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_global\\mnist_plot.png\">\n",
    "\n",
    "<caption><left> Fig 1. Muestra MNIST </left></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = './mnist_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(path=mnist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(50000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_num.shape)\n",
    "print(x_test_num.shape)\n",
    "print(x_train_num[:50000].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir imágenes en vectores, y a float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000, 1)\n",
      "(10000, 784)\n",
      "(10000, 1)\n",
      "(10000, 784)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# set de entrenamiento\n",
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(np.float32)/255 # el -1 es la resultante de multiplicar 28x28\n",
    "y_train = y_train_num[:50000].reshape(50000, 1) # selecciono 50000 en una sola columna\n",
    "\n",
    "# set de validación\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(np.float32)/255\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "\n",
    "# set de prueba\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(np.float32)/255\n",
    "y_test = y_test_num.copy().reshape(10000, 1)\n",
    "\n",
    "# fomas de los set de datos\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar algunas imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image: str) -> None:\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuaciones para nuestro modelo\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal Dos capas 200-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear 'Mini-batches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0])\n",
    "print(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    mb_size = numero de elementos en cada minibatch\n",
    "    x = (numero muestras, 784), corresponde a x_train o el total de elementos para hacer minibatches\n",
    "    y = (numero muestras, 1), corresponde al numro de etiquetas de ese dataset, seria y_train\n",
    "    shuffle = permite hacer un muestreo aleatorio de los datos\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras' #chequea que la forma de x e y sean las mismas\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(input_size: int, neurons: list[int]) -> None:\n",
    "    '''\n",
    "    input_size -> elementos de entrada, es el valor de X o pixeles que son 28*28 = 784\n",
    "    neurons -> list [200, 10] con cantidad de neuronas en cada capa, aca para dos capas.\n",
    "    0.001 : es el valor a multiplicar el numero aleatorio con la finalidad de que sea pequeño, para obtener este valor en profundidad hay\n",
    "    tecnicas, como son las Xavier o Kaiming He.\n",
    "    '''\n",
    "    W1 = np.random.randn(neurons[0], input_size) * 0.001 #neurons corresponde al primero valor de la lista neurons[200, 10]\n",
    "    b1 = np.zeros((neurons[0], 1))\n",
    "    \n",
    "    W2 = np.random.randn(neurons[1], neurons[0]) * 0.001 # es la matriz de la cantidad de neuronas de la segunda capa y la entrada a cada neurona.\n",
    "    b2 = np.zeros((neurons[1], 1))\n",
    "    \n",
    "    return {'W1': W1, 'b1':b1, 'W2':W2, 'b2':b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo para entender el proceso\n",
    "neurons = [7, 5]\n",
    "w1 = np.zeros((neurons[0], 1), dtype=int)\n",
    "print(w1)\n",
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 784)\n",
      "(200, 1)\n",
      "(10, 200)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "parameters = init_parameters(input_size=28*28, neurons=[200, 10])\n",
    "print(parameters['W1'].shape)\n",
    "print(parameters['b1'].shape)\n",
    "print(parameters['W2'].shape)\n",
    "print(parameters['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: np.float64) -> None:\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_types import slice_data\n",
    "\n",
    "def scores_pass(matrizX: slice_data, parameters: dict[type, any], activation_fcn: str) -> None:\n",
    "    '''\n",
    "    función que equivales a: Z = W*x + b\n",
    "    pixel_slice: Corresponde la varible o matriz X. Pix es pixeles, tiene la forma (#pixeles, num samples) es una matriz\n",
    "    paremeters: son los valores de W y b\n",
    "    '''\n",
    "    z1 = parameters['W1'] @ matrizX + parameters['b1'] # el simbolo @ es un shorcut para la multiplicacion de matrices. W1 * x + B\n",
    "    a1 = activation_fcn(z1) # devuelve funcion de activacion\n",
    "    z2 = parameters['W2'] @ a1 + parameters['b2']\n",
    "    \n",
    "    return z2, z1, a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se realiza la traspuesta ya que la matriz W tiene la forma de (200, 784)\n",
    "\n",
    "scores, z1, a1 = scores_pass(matrizX= x_train[:64].T, parameters= parameters, activation_fcn= relu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:64].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:64].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64)\n",
      "(200, 64)\n",
      "(200, 64)\n"
     ]
    }
   ],
   "source": [
    "print(scores.shape)\n",
    "print(z1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(scores.dtype)\n",
    "print(z1.dtype )\n",
    "print(a1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.float64) -> None:\n",
    "    exp_scores = np.exp(x)\n",
    "    sum_exp_scores = np.sum(exp_scores, axis=0) # axis=0 refers to horizontal axis or rows; axis=1 refers to vertical axis or columns\n",
    "    probs = exp_scores/sum_exp_scores\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion cross entropy es la combinacion de softmax + Loss (funcion de perdida individual)\n",
    "def x_entropy(scores: np.float64, y: slice_data, batch_size=64) -> None:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        scores (np.float64): _description_\n",
    "        y (slice_data): Valores correctos\n",
    "        batch_size (int, optional): _description_. Defaults to 64.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    probs = softmax(scores)\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)] # es la prediccion del modelo, cada elemento representa una etiqueta\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size # Funcion de costo en base a todas las imagenes\n",
    "    \n",
    "    return probs, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5]\n",
      " [0]\n",
      " [4]\n",
      " [1]\n",
      " [9]]\n",
      "----\n",
      "(50000, 1)\n",
      "----Esta el la probabilidad de la clase correcta----\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])\n",
    "print('----')\n",
    "print(y_train.shape)\n",
    "print('----Esta el la probabilidad de la clase correcta----')\n",
    "print(y_train.squeeze().shape) # squeeze solo pasa los 50000 elementos, donde cada elemento representa un etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion de retropropagacion\n",
    "def backward(probs: np.float64, x: np.float64, y: slice_data, z1: np.float64, a1: np.float64, \n",
    "                scores: np.float64, parameters: dict[type, any], batch_size=64) -> None:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        probs (np.float64): _description_\n",
    "        x (np.float64): _description_\n",
    "        y (slice_data): _description_\n",
    "        z1 (np.float64): _description_\n",
    "        a1 (np.float64): _description_\n",
    "        scores (np.float64): no sera usada !!\n",
    "        parameters (dict[type, any]): _description_\n",
    "        batch_size (int, optional): _description_. Defaults to 64.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 # y-hat - y\n",
    "    dz2 = probs.copy()\n",
    "    \n",
    "    dW2 = dz2 @ a1.T / batch_size # gradiente funcion de perdida en funcion de W\n",
    "    db2 = np.sum(dz2, axis =1, keepdims=True) / batch_size # gradiente de perdida en funcion de biass\n",
    "    da1 = parameters['W2'].T @ dz2 # gradiente de perdida a la salida de funcion ReLU\n",
    "    \n",
    "    dz1 = da1.copy()\n",
    "    dz1[z1 <= 0 ] = 0\n",
    "    \n",
    "    dW1 = dz1 @ x \n",
    "    db1 = np.sum(dz1, axis=1, keepdims=True) \n",
    "    \n",
    "    assert parameters['W1'].shape == dW1.shape, 'W1 no igual forma'\n",
    "    assert parameters['W2'].shape == dW2.shape, 'W2 no igual forma'\n",
    "    assert parameters['b1'].shape == db1.shape, 'b1 no igual forma'\n",
    "    assert parameters['b2'].shape == db2.shape, 'b2 no igual forma'\n",
    "    \n",
    "    grads = {'w1':dW1,  'b1':db1, 'W2':dW2, 'b2':db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, cost = x_entropy(scores=scores, y=y_train[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3025957449151093\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = backward(probs=y_hat, x=x_train[:64], y=y_train[:64], z1=z1, a1=a1, scores=scores, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x_data:np.float64, y_data:np.float64, mb_size=64) -> None:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x_data, y_data)):\n",
    "        scores2, z1, a1 = scores_pass(x.T, parameters, relu)\n",
    "        y_hat, cost = x_entropy(scores2, y, batch_size=len(x))\n",
    "        \n",
    "        correct += np.sum(np.argmax(y_hat, axis=0) == y.squeeze())\n",
    "        total += y_hat.shape[1]\n",
    "        \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(epochs:np.intc, parameters: dict[type, any], mb_size:int =64, learning_rate:np.float64 = 1e-3) -> None:\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores2, z1, a1 = scores_pass(x.T, parameters=parameters, activation_fcn=relu)\n",
    "            y_hat, cost = x_entropy(scores2, y, batch_size=len(x))\n",
    "            grads = backward(y_hat, x, y, z1, a1, scores2, parameters, batch_size=len(x))\n",
    "            \n",
    "            parameters['W1'] = parameters['W1'] - learning_rate*grads['w1']\n",
    "            parameters['b1'] = parameters['b1'] - learning_rate*grads['b1']\n",
    "            parameters['b2'] = parameters['b2'] - learning_rate*grads['b2']\n",
    "            parameters['W2'] = parameters['W2'] - learning_rate*grads['W2']\n",
    "            \n",
    "        print(f'costo es: {cost}, y accuracy: {accuracy(x_val, y_val, mb_size)}')\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo es: 0.5701089862672033, y accuracy: 0.8673\n",
      "costo es: 0.419081779328062, y accuracy: 0.9031\n",
      "costo es: 0.27873693902986457, y accuracy: 0.915\n",
      "costo es: 0.2649173636712782, y accuracy: 0.9233\n",
      "costo es: 0.32773090594150744, y accuracy: 0.9258\n",
      "costo es: 0.3177769740110869, y accuracy: 0.9313\n",
      "costo es: 0.19304926308378917, y accuracy: 0.9388\n",
      "costo es: 0.2097953865986695, y accuracy: 0.9442\n",
      "costo es: 0.18012280725273627, y accuracy: 0.9463\n",
      "costo es: 0.1672356282479957, y accuracy: 0.9504\n",
      "costo es: 0.22524433819258255, y accuracy: 0.9543\n",
      "costo es: 0.16686709440499536, y accuracy: 0.9556\n",
      "costo es: 0.12977594127267097, y accuracy: 0.9579\n",
      "costo es: 0.120006546507731, y accuracy: 0.9579\n",
      "costo es: 0.17708835029225453, y accuracy: 0.9603\n",
      "costo es: 0.11005491935741253, y accuracy: 0.9605\n",
      "costo es: 0.1263212192436398, y accuracy: 0.9625\n",
      "costo es: 0.10833251146862954, y accuracy: 0.9647\n",
      "costo es: 0.1275327574840075, y accuracy: 0.965\n",
      "costo es: 0.13207740508590846, y accuracy: 0.9657\n"
     ]
    }
   ],
   "source": [
    "mb_size = 512 # minibatches\n",
    "learning_rate = 1e-2\n",
    "epochs = 20\n",
    "\n",
    "parameters = train(epochs=epochs, parameters=parameters, mb_size=mb_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96988"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_data=x_train, y_data=y_train, mb_size=mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9648"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_data=x_test, y_data=y_test, mb_size=mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x) -> None:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        x (_type_): parametro que corresponde a la imagen a recibir, para predecir\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    scores2, _, _ = scores_pass(matrizX=x, parameters=parameters, activation_fcn=relu)\n",
    "    return np.argmax(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].reshape(-1, 1).shape # transporfa la forma (784,) a la forma (784,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor predicho es: 5\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "\n",
    "pred = predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this # PEP 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
